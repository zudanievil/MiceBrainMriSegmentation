{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/zudanievil/MiceBrainMriSegmentation/blob/paper/ipynb/example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open this notebook in Google Colab\"/></a>\n",
    "\n",
    "This notebook can run in Google Colab with no prior setup.\n",
    "You can also run it on a local python installation, but you will need to change some CAPITAL_CASE constants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gRoa0Fl8tDL-"
   },
   "source": [
    "# Mice Brain Mri Segmentation #\n",
    "(actually, it can segment human scans as well. the repo name is a bit underthought)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56C-1p2ktDMD"
   },
   "source": [
    "## Overview ##\n",
    "* These scripts allow to finenly segment raster images (MRI scans) using svg images (from histological brain atlas).\n",
    "* Atlas svg images and some other assets are retrieved from Allen Brain Institute web-service, which is free for academic and personal use.\n",
    "    * [Allen Brain Institute website](https://portal.brain-map.org/)\n",
    "    * [Mouse | Human brain atlases](http://atlas.brain-map.org/)\n",
    "    * [Allen Brain Institute API help](http://help.brain-map.org/display/api/Allen+Brain+Atlas+API)\n",
    "* This repository contains a collection of cohesive scripts, **not a Python package or an application**. One should know Python to use this.\n",
    "\n",
    "---\n",
    "\n",
    "This notebook will guide through one through the path to replicate our work:\n",
    "1. [installing nesessary programs](#1.-Installations)\n",
    "1. [creating folders](#2a.-creating-folders) and nessesary files\n",
    "1. [manually segmenting the brains from the scans](#3.-manual-scan-segmentation)\n",
    "1. [bulk-downloading atlas images](#4a.-downloading-atlas-images) and generating raster masks from them\n",
    "1. [preprocessing scans before fine segmentation](#5.-preprocessing-scans)\n",
    "1. [fine-segmenting brains into anatomical regions](#6.-fine-anatomical-segmentation)\n",
    "1. [postprocessing segmentation results](#7.-aftermath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jGAJVyzbtDME"
   },
   "source": [
    "## 1. Installations\n",
    "This notebook can run in [`GOOGLE COLAB`](https://colab.research.google.com/github/zudanievil/MiceBrainMriSegmentation/blob/paper/ipynb/example.ipynb) with no prior setup, but it is best to run it on a locally installed python.\n",
    "\n",
    "To do this on a local machine:\n",
    "1. clone this repository\n",
    "1. install [Anaconda] package manager\n",
    "1. [create virtual environment from the file] named `conda_env.yml` contained in this repository\n",
    "1. install [Inkscape], install [ImageJ]\n",
    "1. it is best to install [PyCharm] for code editing, and [set up PyCharm to use Anaconda virtual environment]\n",
    "\n",
    "[Anaconda]: https://www.anaconda.com/products/individual\n",
    "[create virtual environment from the file]: https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#creating-an-environment-from-an-environment-yml-file\n",
    "[PyCharm]: https://www.jetbrains.com/pycharm/download/\n",
    "[set up PyCharm to use Anaconda virtual environment]: https://www.jetbrains.com/help/pycharm/conda-support-creating-conda-virtual-environment.html\n",
    "[Inkscape]: https://inkscape.org/\n",
    "[ImageJ]: https://imagej.nih.gov/ij/download.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XpSmvXKUtDMH"
   },
   "source": [
    "### imports & utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "or9_7gpKtDMK"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "from zipfile import ZipFile\n",
    "import yaml\n",
    "from shutil import copy as file_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "id": "AYtF9f3AtDMH"
   },
   "outputs": [],
   "source": [
    "# @markdown some generic utility functions, used throughout the notebook\n",
    "\n",
    "def unzip(src: Path, dst: Path):\n",
    "    \"\"\"unzip a `.zip file located at `src` into `dst` folder\"\"\"\n",
    "    with ZipFile(src, 'r') as z:\n",
    "        z.extractall(dst)\n",
    "    \n",
    "    \n",
    "def rmdir_rec(folder: Path): #why didn't they implement it in the pathlib?\n",
    "    \"\"\"removes `folder` with all the contents\"\"\"\n",
    "    for f in folder.iterdir():\n",
    "        rmdir_rec(f) if f.is_dir() else f.unlink()\n",
    "    folder.rmdir()\n",
    "    \n",
    "    \n",
    "def merge_folders(src: Path, dst: Path, matching_files_policy: {\"skip\", \"replace\", \"rename\", \"error\"} = \"replace\"):\n",
    "    \"\"\"\n",
    "    recursively copies contents from the `src` folder to `dst` folder.\n",
    "    if files match, uses `matching_files_policy`:\n",
    "        - skip\n",
    "        - replace\n",
    "        - error: raises FileExistsError\n",
    "        - rename: adds \".copy\" suffix to filename, eg `a.txt` -> `a.copy.txt`\n",
    "    \"\"\"\n",
    "    assert matching_files_policy in {\"skip\", \"replace\", \"rename\", \"error\"}\n",
    "    \n",
    "    for path_src in src.iterdir():\n",
    "        path_dst = dst / path_src.name\n",
    "        if path_src.is_dir():\n",
    "            path_dst.mkdir(exist_ok=True)\n",
    "            merge_folders(path_src, path_dst, matching_files_policy)\n",
    "        else:\n",
    "            if path_dst.exists():\n",
    "                if matching_files_policy == \"error\":\n",
    "                    raise FileExistsError(path_dst)\n",
    "                elif matching_files_policy == \"replace\":\n",
    "                    path_dst.unlink()\n",
    "                elif matching_files_policy == \"rename\":\n",
    "                    while path_dst.exists():\n",
    "                        path_dst = path_dst.parent / (path_dst.stem + \".copy\" + path_dst.suffix)\n",
    "                else:\n",
    "                    continue\n",
    "            file_copy(path_src, path_dst)\n",
    "\n",
    "\n",
    "def fetch_unpack_zip(url: str, dst: Path) -> \"http message\":\n",
    "    \"\"\"\n",
    "    fetches example data from the cloud, \n",
    "    :returns http.client.HTTPMessage\n",
    "    \"\"\"\n",
    "    zip, msg = urlretrieve(url)\n",
    "    zip = Path(zip)\n",
    "    unzip(src=zip, dst=dst)\n",
    "    zip.unlink()\n",
    "    return msg\n",
    "\n",
    "\n",
    "def fetch_github_repo(\n",
    "    user: str, repo: str, branch: str, \n",
    "    dst_dir: Path, compression: {\"zipball\", \"tarball\"} = \"zipball\",\n",
    ") -> (str, \"http message\"):\n",
    "    url = f\"https://api.github.com/repos/{user}/{repo}/{compression}/{branch}\" \n",
    "    # https://docs.github.com/en/rest/reference/repos#download-a-repository-archive-tar\n",
    "    dst_dir = Path(\"/content\") \n",
    "    \n",
    "    zipball, msg = urlretrieve(url)\n",
    "    unzip(src=Path(zipball), dst=dst_dir)\n",
    "    Path(zipball).unlink()\n",
    "    for p in dst_dir.iterdir():\n",
    "        if p.name.startswith(f\"{user}-{repo}\"):\n",
    "            # there is a seemingly random number at the end of the folder name\n",
    "            new_p = p.parent / f\"{user}-{repo}\"\n",
    "            p.rename(new_p)\n",
    "            return str(new_p), msg\n",
    "\n",
    "\n",
    "def file_backup(p: Path):\n",
    "    file_copy(p, p.parent / (p.name + \".backup\"))\n",
    "\n",
    "\n",
    "def modify_info_folder_config(info_instance, keys: list, value: any):\n",
    "    config = info_instance.configuration()\n",
    "    config_path = info_instance.configuration_path()\n",
    "\n",
    "    c = config\n",
    "    for k in keys[0:-1]:\n",
    "        c = c[k]\n",
    "    c[keys[-1]] = value\n",
    "\n",
    "    with config_path.open(\"wt\") as f:\n",
    "        yaml.safe_dump(config, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RW_eDJH1tDMJ"
   },
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VffZto_ftDMK"
   },
   "outputs": [],
   "source": [
    "RUNTIME_IS_ON_GOOGLE_COLAB: bool = \"google.colab\" in sys.modules\n",
    "\n",
    "\n",
    "WORKING_DIR = \"/content/example\" if RUNTIME_IS_ON_GOOGLE_COLAB \\\n",
    "    else YOUR_TEMP_DIRECTORY  # if you run this locally, define your temp directory \n",
    "\n",
    "\n",
    "# if on google colab, fetch whole repository from github\n",
    "if RUNTIME_IS_ON_GOOGLE_COLAB:\n",
    "    MBS_LIB_PATH, msg = fetch_github_repo(\n",
    "        user = \"zudanievil\",\n",
    "        repo = \"MiceBrainMriSegmentation\",\n",
    "        branch = \"paper\",\n",
    "        dst_dir = Path(\"/content\") # google VM directory for user contents\n",
    "    )\n",
    "    rmdir_rec(Path(\"/content/sample_data\")) # remove some toy datasets provided by google\n",
    "\n",
    "else:\n",
    "    MBS_LIB_PATH = \"../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yEDVPVps77pf",
    "outputId": "285a02b6-eadb-43a4-c8c0-882f31ddb09a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
      "\n",
      "Extracting templates from packages: 100%\n",
      "Inkscape 0.92.3 (2405546, 2018-03-11)\n"
     ]
    }
   ],
   "source": [
    "# set path to inkscape executable\n",
    "\n",
    "if RUNTIME_IS_ON_GOOGLE_COLAB:\n",
    "    !apt install inkscape -y 2>&1 > /dev/null\n",
    "    !inkscape --version\n",
    "    INKSCAPE_EXE = \"inkscape\"\n",
    "else:\n",
    "    INKSCAPE_EXE = ...  # if you run this notebook locally, you need to paste your shell command for inkscape here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_JJnBUe9tDML"
   },
   "source": [
    "## 2a. creating folders ##\n",
    "classes `IC.ImageFolderInfo`, `IC.OntologyFolderInfo`, `IC.SegmentationResultsFolderInfo` contain `.write()` method that allows to conveniently create these folders in the filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ZIlROTRtDML"
   },
   "outputs": [],
   "source": [
    "working_dir = Path(WORKING_DIR)\n",
    "temp_dir = (working_dir / \"temp\").resolve()\n",
    "\n",
    "\n",
    "working_dir.mkdir(exist_ok=False)\n",
    "temp_dir.mkdir(exist_ok=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2ZIlROTRtDML"
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, MBS_LIB_PATH)\n",
    "from mbs_lib.core import info_classes as IC\n",
    "\n",
    "\n",
    "infos = {}\n",
    "\n",
    "infos[\"ontology\"] = IC.OntologyFolderInfo(working_dir/\"ontology\")\n",
    "infos[\"ontology\"].write()\n",
    "\n",
    "for i in {1, 2}:\n",
    "    \n",
    "    infos[f\"images_{i}\"] = IC.ImageFolderInfo(working_dir / f\"images_{i}\")\n",
    "    infos[f\"images_{i}\"].write()\n",
    "\n",
    "    infos[f\"results_{i}\"] = IC.SegmentationResultFolderInfo(\n",
    "        infos[f\"images_{i}\"], infos[\"ontology\"], folder=working_dir / f\"results_{i}\")\n",
    "    infos[f\"results_{i}\"].write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rS3z1kk7tDML"
   },
   "source": [
    "## 2b. putting files into image folder ##\n",
    "* `lib/default_specifications` folder has configuration files that are copied by the `.write()` methods of info classes into the directory that they create. These are YAML files, that can be used to correct the `lib.pipelines` modules' behaviour.\n",
    "* `image_folder_specification.yml` that was is created in `c:/users/user/example/img` must be edited.\n",
    "* under the `file_name_fields` key there is a list of strings, that compose any file name that is related to image. one should give these fields names that correspond to current experiment parameters, like time, mice strain, etc.\n",
    "    > e.g. if configuration looks like this:\n",
    "    file_name_fields:\n",
    "        - a\n",
    "        - b\n",
    "        - c\n",
    "    then image file names are assumed to look like `{a}_{b}_{c}.npy`, and metadata names like `{a}_{b}_{c}.yml`. these names will be broken down by some scripts into \"dictionaries\" of {field_name: field_value}. For instance, name 10_20_xyz.npz will correspond to {\"a\":\"10\", \"b\":\"20\", \"c\":\"xyz\"}.  **It is possible to adjust cropped scan resolution based on the value of \"frame\" field through editing `cropped_image_shapes` in the image folder configuration.**\n",
    "* After that transfer the images into the `img_raw` subfolder of image folder, rename them according to the fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ti5lv0rG1dnu"
   },
   "source": [
    "**For demonstration purposes a small portion of our data is retrieved and visualized below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dOT9Neh1tDMM"
   },
   "outputs": [],
   "source": [
    "fetch_unpack_zip(\"https://drive.google.com/uc?export=download&id=1sqmcICO01UdB6WUxvYcVsJVNlnvAVKBS\", temp_dir)\n",
    "example_data = temp_dir / \"example\"\n",
    "\n",
    "merge_folders(example_data, working_dir, \"replace\")\n",
    "rmdir_rec(example_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-H4SVL4tDMM"
   },
   "source": [
    "## 3. manual scan segmentation ##\n",
    "* manual scan segmentation is done by ImageJ program.\n",
    "* the result of the segmentation for each image is couple files that contain digits separated by tabulations and newlines (ImageJ scripts do not have sophisticated tools for file parsing and formatting). These files are collected by a python script into a single YAML metadata file, based on the values under `metadata keys` in the image folder configuration.\n",
    "* to segment images do the following:\n",
    "    1. make list of file names in `img_raw` subfolder, put it in the `ij_img_list.txt` file in the image folder, separated by newlines (only names, not the full paths). Create `ij_pointer.txt`, put 0 into it. Here is an easy way to o this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "M4f_93bZtDMM"
   },
   "outputs": [],
   "source": [
    "def list_raw_images(ifi: IC.ImageFolderInfo):\n",
    "    img_list_fname = ifi.folder()/\"ij_img_list.txt\"\n",
    "    img_idx_fname = ifi.folder()/\"ij_pointer.txt\"\n",
    "\n",
    "    with open(img_list_fname, \"wt\") as f:\n",
    "        for img in ifi.raw_iter():\n",
    "            print(img.name(), file=f)\n",
    "            \n",
    "    with open(img_idx_fname, \"wt\") as f:\n",
    "        print(0, file=f)\n",
    "\n",
    "\n",
    "for i in {1, 2}:\n",
    "    list_raw_images(infos[f\"images_{i}\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KG5AzfTn96_a"
   },
   "source": [
    "**Manual segmentation results in `.txt` files, which were fetched earlier along with images.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZfXPsLDbtDMM"
   },
   "source": [
    "*   \n",
    "   2. Open the `lib/imagej_scripts/brain_segmentation_with_imagej.txt`, edit command for image opening according to [ImageJ macro guide] and [ImageJ macro functions list] to open your images (the function below comment `//IMAGE OPENING FUNCTION`). Initially it opens 32bit little-endian single channel 256x256, written as a C-array.\n",
    "   1. Open imagej, load that file as imagej macro: `macros > install > imagej`\n",
    "   1. Press `h` to open log window with the instructuions. follow the instructions.\n",
    "   1. Run collect `collect_image_metadata.main()` (cell below)\n",
    "   >you can find about metadata collection process and how to tune it with configuration editing if you run `help(collect_image_metadata.main)`\n",
    "   \n",
    "[ImageJ macro guide]: https://imagej.nih.gov/ij/developer/macro/macros.html#tools\n",
    "[ImageJ macro functions list]: https://imagej.nih.gov/ij/developer/macro/functions.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "z_BatC7atDMN"
   },
   "outputs": [],
   "source": [
    "from mbs_lib.pipelines import collect_image_metadata\n",
    "for i in {1, 2}:\n",
    "    collect_image_metadata.main(infos[f\"images_{i}\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-wX4a02tDMN"
   },
   "source": [
    "## 4a. downloading atlas images ##\n",
    "variables for downloading are stored in `ontology_folder_specification.yml` file inside ontology folder that you've created above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GjiLdnwtDMN"
   },
   "source": [
    "1. Edit `atlas_id` and `svg_groups` (a table of them can be found [here](http://help.brain-map.org/display/api/Atlas+Drawings+and+Ontologies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_-y82JYetDMN",
    "outputId": "c37179a7-a979-48bd-b2e3-1864807ca571"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default ontology written to /content/example/ontology/onts/default.xml\n"
     ]
    }
   ],
   "source": [
    "from mbs_lib.pipelines import download_svgs\n",
    "download_svgs.download_default_ontology(infos[\"ontology\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejwmY-GstDMO"
   },
   "source": [
    "2. Edit the `slice_coordinates` if you know the coordinates for the first slice and the last slice in the atlas. this allows you to download a list of slice ids and zip it with coordinate range using a script in the cell below (the table is just for utility purposes, you can skip this step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZKEvwOzFtDMO",
    "outputId": "b452c4c0-55a6-4e1a-fb7b-e87369e0fcb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved section ids to /content/example/ontology/slice_ids.txt\n"
     ]
    }
   ],
   "source": [
    "download_svgs.download_slice_ids_table(infos[\"ontology\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FfC_EobxtDMO"
   },
   "source": [
    "Now you have a very readable (for an xml) `default.xml` tree of structures for the atlas, and probably a tabulation-separated table of slice ids.\n",
    "For each frame value in image names there should be an svg image with the same name. fill the ontology folder configuration  `svg_names_and_slice_ids` with pairs of `frame_field_value: slice_id`. run the script from the cell below to bulk-download the atlas vector images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sxMsAppptDMO",
    "outputId": "17d60652-225e-464e-c648-c761ba1ddcfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaded: /content/example/ontology/svgs/f14_downloaded.svg\n",
      "downloaded: /content/example/ontology/svgs/f17_downloaded.svg\n"
     ]
    }
   ],
   "source": [
    "# we've renamed the files in ontology folder config \n",
    "# so that they wouldn't overwrite svgs downloaded with example\n",
    "# feel free to explore the differences\n",
    "download_svgs.download_svgs(infos[\"ontology\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZztwBF4FtDMO"
   },
   "source": [
    "You can and need to manually edit the `.svg` masks with Inkscape, but note that some Inkscape functions can alter all xml attributes of the paths. structures for rendering are found by `structure_id` attributes of the paths, make sure, they are not deleted in the editing process.\n",
    "1. I advise to compute mean of all images for each frame and put it into a corresponding svg (the rendering pipeline ignores visible objects that do not have `structure_id` attribute, so you can leave image there).\n",
    "2. You **must** create a rectangle with xml attribute `structure_id='bbox'`, that will mark the border of the rendered masks (to edit xml attributes of objects from Inkscape, open the 'xml editor' tab.\n",
    "3. It's a good idea to slightly adjust nodes of atlas structures to fit the contours of the brain.\n",
    "4. Note that you can specify an arbitrary function to modify each mask right before the scan segmentation. Therefore you do need to flip/copy/crop the svg masks if only one hemisphere is covered and you need masks for both hemisperes, or otherwise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RpuNvNuGtDMP"
   },
   "source": [
    "## 4b. rendering raster masks ##\n",
    "For this one needs to edit `inkscape_executable_path` value in the ontology folder's configuration. \n",
    "The rendering pipeline uses image folder configuration `cropped_image_shapes` values for determining mask sizes.\n",
    "Details about process can be found in `prerender_masks.main` function documentation. This process might take several hours, but is easily parallelized by calling pipeline from different processes for only a part of all frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "oiByW_W2JjtQ"
   },
   "outputs": [],
   "source": [
    "# let's set up inkscape executable command:\n",
    "file_backup(infos[\"ontology\"].configuration_path())\n",
    "modify_info_folder_config(\n",
    "    info = infos[\"ontology\"], \n",
    "    keys = [\"rendering_constants\", \"inkscape_executable\"], \n",
    "    value = INKSCAPE_EXE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zlWDvgr8tDMP",
    "outputId": "8d1853ce-98f2-4b3c-ed4a-c2f675cd0262"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rendering for f14: 100%|█████████▉| 1326/1327 [00:24<00:00, 112.42it/s, Retina]               \n",
      "Total found structures 78\n",
      "rendering for f17: 100%|█████████▉| 1326/1327 [00:07<00:00, 144.27it/s, Retina]               \n",
      "Total found structures 15\n"
     ]
    }
   ],
   "source": [
    "from mbs_lib.pipelines import prerender_masks\n",
    "# prerender_masks needs `ImageFolderInfo` configuration file to acqire shapes for masks.\n",
    "# we will use masks prerendered for image folder 1 for both folder 1 and folder 2. \n",
    "prerender_masks.main(infos[\"ontology\"], infos[\"images_1\"], frames = [\"f14\", \"f17\"]) # we specify frames so that only these svgs will be used for mask generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "99SYXawstDMP"
   },
   "source": [
    "## 5. preprocessing scans ##\n",
    "* Convert images to numpy native array format via `numpy.save()`, put them into `img` subfolder of the image folder.\n",
    "\n",
    "* The pipeline called below uses `cropped_image_shapes` key of the configuration and `frame` field value in the image name as well as some metadata keys to crop and resize the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "cIeXrLigCjDs"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def convert_raw_to_npy(ifi: IC.ImageFolderInfo, dtype=\"<i4\", shape=(256, 256)):\n",
    "    for img_info in ifi.raw_iter():\n",
    "        img = img_info.raw_image(dtype=dtype, shape=shape)\n",
    "        np.save(img_info.image_path(), img)\n",
    "\n",
    "\n",
    "for i in {1, 2}:\n",
    "    convert_raw_to_npy(infos[f\"images_{i}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nlljZn81tDMP",
    "outputId": "b8750d8d-206b-4e95-ef39-1699199f7d43"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from mbs_lib.pipelines import crop_images\n",
    "\n",
    "for i in {1, 2}:\n",
    "    crop_images.main(infos[f\"images_{i}\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vjMrugItDMP"
   },
   "source": [
    "To normalize image by intensity, we generate reference values and put them into metadata files. Later on you can choose which key to to use for image normalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "speUA0jQtDMP",
    "outputId": "92d5cfa2-7006-4208-cf35-7b4b47a90757"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from mbs_lib.pipelines import generate_intensity_reference\n",
    "\n",
    "for i in {1, 2}:\n",
    "    generate_intensity_reference.main(infos[f\"results_{i}\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AoJALY6ptDMQ"
   },
   "source": [
    "## 6. fine anatomical segmentation\n",
    "1. You need to specify a tabulation-separated table which contains names of images. Table header specifies, from which columns images fall into 'control' group and from which -- into the 'effect' group. images from the one row constitute a batch and are compared against each other. the `batch_for_comparison` pipeline can create this table. Note that one can easily edit this table in MS Excel/Libre Office, etc.\n",
    "You can find about how to control pipeline behaviour through a result folder configuration in the `batch_for_comparison.main` description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Y3a3ZUqcXyX7"
   },
   "outputs": [],
   "source": [
    "# change reference hour and title for debugging plots\n",
    "\n",
    "ref_hour = \"3\"\n",
    "plot_title_fstring = \"3h vs {hour}, frame: {frame} p-value and mean relative intensity\"\n",
    "\n",
    "for i in {1, 2}:\n",
    "    file_backup(infos[f\"results_{i}\"].configuration_path())\n",
    "    modify_info_folder_config(\n",
    "        info = infos[f\"results_{i}\"], \n",
    "        keys = [\"batching\", \"comparison_reference_value\"], \n",
    "        value = ref_hour,\n",
    "    )\n",
    "    modify_info_folder_config(\n",
    "        info = infos[f\"results_{i}\"],\n",
    "        keys = [\"comparison\", \"plot_title\"],\n",
    "        value = plot_title_fstring,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "tIcojlfptDMQ"
   },
   "outputs": [],
   "source": [
    "from mbs_lib.pipelines import batch_for_comparison\n",
    "\n",
    "for i in {1, 2}:\n",
    "    batch_for_comparison.main(infos[f\"results_{i}\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwAvtxratDMR"
   },
   "source": [
    "2. please read the `compare_and_segment.main` help for detalis on how to control it's behaviour with configuration file and some other files, that can be created in the `spec` subfolder of results folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3grIzJBcbpcn",
    "outputId": "7fd3fc22-5dc3-4bc2-cb39-9d42cbee9e6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function main in module mbs_lib.pipelines.compare_and_segment:\n",
      "\n",
      "main(segmentation_result_folder_info: Union[ForwardRef('SegmentationResultFolderInfo'), pathlib.Path, str], batch_range: slice = None, save_intersection_images: bool = True)\n",
      "    for each batch of animals (see `pipelines.batch_for_comparison`)\n",
      "    1. compare images with specified statistic (see results folder configuration, `comparison/image_comparison_type`)\n",
      "    2. plot p-values (false positive rate), difference between images (if `save_intersection_images=True`)\n",
      "    3. for differen p-value levels (see configuration `comparison/pval_thesholds`),\n",
      "    calculate number of significant pixels, mean and standard deviation.\n",
      "    calculated statistics are stored in \"pickled\" DataFrames,\n",
      "    they need to be aggregated by `pipelines.compare_and_segment.collect_segmentation_results` function\n",
      "    \n",
      "    NB: one can specify a set of anatomical structures to use in the file\n",
      "    at location given by `segmentation_results_folder_info.structure_list_path()`.\n",
      "    the structures must be provided as newline-separated list.\n",
      "    \n",
      "    NB: one can also make \"mask_permutation.py\" script that will specify how to permute structure mask\n",
      "    (2d numpy boolean array) the script must contain entry\n",
      "    function `mask_permutation(x: numpy.ndarray) -> numpy.ndarray`.\n",
      "    The location of such file is specified by `segmentation_results_folder_info.mask_permutation_path()`\n",
      "    \n",
      "    You can influence how the atlas mask is applied to the images by editing `mask_permutation.py`\n",
      "    file in the results folder.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mbs_lib.pipelines import compare_and_segment\n",
    "help(compare_and_segment.main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KLAkQJM6tDMR",
    "outputId": "5b32226c-4f97-4310-893f-cb7bb9709d7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: results_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s, 0]/content/zudanievil-MiceBrainMriSegmentation/mbs_lib/pipelines/compare_and_segment.py:185: UserWarning: No contour levels were found within the data range.\n",
      "  axs[0].contour(structure_mask, **spec['contour_kwargs'])\n",
      "/content/zudanievil-MiceBrainMriSegmentation/mbs_lib/pipelines/compare_and_segment.py:186: UserWarning: No contour levels were found within the data range.\n",
      "  axs[1].contour(structure_mask, **spec['contour_kwargs'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: results_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from mbs_lib.pipelines import compare_and_segment\n",
    "\n",
    "for i in {1, 2}:\n",
    "    print(f\"processing: results_{i}\")\n",
    "    compare_and_segment.main(infos[f\"results_{i}\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ldUty6atDMR"
   },
   "source": [
    "3. segmentation results are saved into a temporary folder to save RAM and allow parallel execution (by running several processes and supplying `batch_range` argument to  `compare_and_segment.main`). Because of this design choice, segmentation results' pieces are aggregated by a separate function. You also need to delete temp folder yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "gO1tMgHItDMS"
   },
   "outputs": [],
   "source": [
    "# %%debug -b /content/zudanievil-MiceBrainMriSegmentation-c417baf/mbs_lib/pipelines/compare_and_segment.py:307\n",
    "for i in {1, 2}:\n",
    "    compare_and_segment.collect_segmentation_results(infos[f\"results_{i}\"])\n",
    "    # rmdir_rec(infos[f\"results_{i}\"].segmentation_temp())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FvGXELz3tDMS"
   },
   "source": [
    "## 7. aftermath\n",
    "There are some scripts for processing the results table. Consult with their descriptions to understand what do they do.\n",
    "also there is an execute_all script, that just calls them in a logical order (some scripts depend on each other). They also use configuration for the results folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "4Dxa8O3PtDMS"
   },
   "outputs": [],
   "source": [
    "structures = (\n",
    "    'Main Olfactory Bulb',\n",
    "    'Olfactory Nerve',\n",
    "    'Anterior Olfactory Nucleus',\n",
    "    'Piriform Area',\n",
    "    'Piriform-Amygdalar Area',\n",
    "    'Cortical Amygdalar Area',\n",
    "    'Entorhinal Area',\n",
    "    'Olfactory Tubercle',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "id": "qRwx_fEgtDMS",
    "outputId": "60f9834f-6b39-4e53-8e7a-aaa13b768b91"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/zudanievil-MiceBrainMriSegmentation/mbs_lib/pipelines/segmentation_results_processing.py:66: UserWarning: make_kinetics_table subpipeline have not been generalized for arbitrary filename fields, please inspect code\n",
      "  warnings.warn(message='make_kinetics_table subpipeline have not been generalized '\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-6856386a00bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msegmentation_results_processing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"results_{i}\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/content/zudanievil-MiceBrainMriSegmentation/mbs_lib/pipelines/segmentation_results_processing.py\u001b[0m in \u001b[0;36mexecute_all\u001b[0;34m(segmentation_result_folder_info, structure_list_for_significance_table)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0msrfi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfo_classes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSegmentationResultFolderInfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegmentation_result_folder_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mrefactor_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrfi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mmake_kinetics_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrfi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mmake_significance_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrfi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstructure_list_for_significance_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mplot_segmentation_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrfi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/zudanievil-MiceBrainMriSegmentation/mbs_lib/pipelines/segmentation_results_processing.py\u001b[0m in \u001b[0;36mmake_kinetics_table\u001b[0;34m(segmentation_result_folder_info)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mload_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrfi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'segm_result.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrfi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'kinetic_table.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrfi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfiguration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'comparison'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'normalize_image_by'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'normalize_image_by'"
     ]
    }
   ],
   "source": [
    "from mbs_lib.pipelines import segmentation_results_processing\n",
    "\n",
    "for i in {1, 2}:\n",
    "    segmentation_results_processing.execute_all(infos[f\"results_{i}\"])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
