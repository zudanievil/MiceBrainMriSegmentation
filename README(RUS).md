#### Установка:
1. клонировать (скачать) этот репозиторий
2. установить менеджер пакетов [Anaconda]. [инструкция по установке на windows]
3. [создать виртуальную среду] из файла conda_env.yml
4. желательно установить [PyCharm] (для редактирования кода), [настроить PyCharm для работы со средой Anaconda]

[Anaconda]: https://www.anaconda.com/products/individual
[инструкция по установке на windows]: https://docs.anaconda.com/anaconda/install/windows/
[создать виртуальную среду]: https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#creating-an-environment-from-an-environment-yml-file
[PyCharm]: https://www.jetbrains.com/pycharm/download/
[настроить PyCharm для работы со средой Anaconda]: https://www.jetbrains.com/help/pycharm/conda-support-creating-conda-virtual-environment.html

#### Использование:
1. Предполагается, что для использования нужно написать короткий скрипт на python (рабочие примеры есть в папке scripts).
2. Скрипты активируются через командную оболочку системы сконфигурированную Anaconda.
(на windows в меню start после инсталляции есть опция Anaconda prompt, 
на linux Anaconda конфигурирует bash автоматически при запуске)
3. После запуска оболочки необходимо активировать среду командой `conda activate brainS`
4. Скрипт активируется командой типа `python "c:/users/user/desktop/MiceBrainMriSegmentation/scripts/example_script.py"`
* Писать скрипты, которые принимают аргументы командной строки -- так себе идея, проще менять скрипт каждый раз
или завести новый.

#### Основные идеи:
* Данные, обрабатываемые вместе, хранятся внутри одной папки (project_folder),
каждый вид данных в собственной подпапке
* Программы могут изменять только эти целевые папки, желательно только 1-2 подпапки за раз
* Папки проектов, внутри к-рых хранятся похожие данные имеют одинаковую структуру.
* Имена имеют значение. Если не делать паттерн-мэтчинг по именам, нужно будет составлять
крайне длинные списки файлов для обработки и передавать их в функцию.
Поэтому: метаданные к изображению должны иметь то же имя, что и изображение
(изображение: `abracadabra.npy`, метаданные: `abracadabra.yml`),
то же самое касается масок и списков структур (онтологий) и вообще всего-всего.
* Паттерн-мэтчинг -- это круто.
---
* Массивы хранятся в виде изображений или файлов .npy, .npz, к-рые [читаются библиотекой numpy].
Не надо их хранить в виде двоичных строк, оставим это программистам с/с++.
* таблицы хранятся в виде csv файлов c разделителем `\t` (табуляция).
* файлы, предназначенные только для чтения с помощью python хранятся в виде
сериализованных объектов python, с расширениями .pickle, .pth (для pytorch).
* Конфигурация/древовидные структуры данных хранятся в [.yml] или .xml файлах.
* .yml файлы просто править в любом редакторе кода, они хорошо читаются человеком, лучше использовать их.
* Константы к модулям библиотеки хранятся в одном файле .yml, в виде словаря (хэш-таблицы).
Ключи внешнего уровня совпадают с именами .py файлов библиотеки + есть общий ключ 'global'.
Данные с ключом `filename` загружаются в переменную `filename._LOC`, с ключом `global` --
в переменную `filename._GLOB`.

[читаются библиотекой numpy]: https://numpy.org/devdocs/reference/generated/numpy.lib.format.html
[.yml]: https://en.wikipedia.org/wiki/YAML

---
* Если какие-то данные могут обрабатываться отдельно, лучше обрабатывать их отдельно,
сохраняя промежуточный результат. Даже если промежуточный результат -- дамп памяти.
* Чем меньше ветвлений в потоке выполнения, тем проще дебажить, и тем меньше вероятность ошибок в рантайме.
* Хуже ошибок в рантайме -- запись рандомных данных. Необходимо исключать возможность смешивания старых и новых данных,
проверяя наличие старых данных при помощи инструкций типа assert и тп.
