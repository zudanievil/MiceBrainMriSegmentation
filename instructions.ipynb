{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mice Brain Mri Segmentation #\n",
    "(actually, it can segment human scans as well. the repo name is a bit underthought)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview ##\n",
    "* These scripts allow to finenly segment raster images (MRI scans) using svg images (from histological brain atlas).\n",
    "* Atlas svg images and some other assets are retrieved from Allen Brain Institute web-service, which is free for academic and personal use.\n",
    "    * [Allen Brain Institute website](https://portal.brain-map.org/)\n",
    "    * [Mouse | Human brain atlases](http://atlas.brain-map.org/)\n",
    "    * [Allen Brain Institute API help](http://help.brain-map.org/display/api/Allen+Brain+Atlas+API)\n",
    "* This repository contains a collection of cohesive scripts, **not a Python package or an application**. One should know Python to use this.\n",
    "\n",
    "---\n",
    "\n",
    "This notebook will guide through one through the path to replicate our work:\n",
    "1. [installing nesessary programs](#1.-Installations)\n",
    "1. [creating folders](#2a.-creating-folders) and nessesary files\n",
    "1. [manually segmenting the brains from the scans](#3.-manual-scan-segmentation)\n",
    "1. [bulk-downloading atlas images](#4a.-downloading-atlas-images) and generating raster masks from them\n",
    "1. [preprocessing scans before fine segmentation](#5.-preprocessing-scans)\n",
    "1. [fine-segmenting brains into anatomical regions](#6.-fine-anatomical-segmentation)\n",
    "1. [postprocessing segmentation results](#7.-aftermath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installations\n",
    "This notebook can run in [GOOGLE COLAB](https://colab.research.google.com/github/zudanievil/MiceBrainMriSegmentation/blob/paper/instructions.ipynb) with no prior setup, but it is best to run it on a locally installed python.\n",
    "\n",
    "To do this on a local machine:\n",
    "1. clone this repository\n",
    "1. install [Anaconda] package manager\n",
    "1. [create virtual environment from the file] named `conda_env.yml` contained in this repository\n",
    "1. install [Inkscape], install [ImageJ]\n",
    "1. it is best to install [PyCharm] for code editing, and [set up PyCharm to use Anaconda virtual environment]\n",
    "\n",
    "[Anaconda]: https://www.anaconda.com/products/individual\n",
    "[create virtual environment from the file]: https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#creating-an-environment-from-an-environment-yml-file\n",
    "[PyCharm]: https://www.jetbrains.com/pycharm/download/\n",
    "[set up PyCharm to use Anaconda virtual environment]: https://www.jetbrains.com/help/pycharm/conda-support-creating-conda-virtual-environment.html\n",
    "[Inkscape]: https://inkscape.org/\n",
    "[ImageJ]: https://imagej.nih.gov/ij/download.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "YOUR_TEMP_DIRECTORY = \"/home/admin/Documents/lab/example\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from zipfile import ZipFile\n",
    "from shutil import copy as file_copy\n",
    "# some utility functions\n",
    "\n",
    "def unzip(src: Path, dst: Path):\n",
    "    \"\"\"unzip a `.zip file located at `src` into `dst` folder\"\"\"\n",
    "    with zipfile.ZipFile(path_to_zip_file, 'r') as z:\n",
    "        z.extractall(dst)\n",
    "    \n",
    "    \n",
    "def rmdir_rec(folder: Path): #why didn't they implement it in the pathlib?\n",
    "    \"\"\"removes `folder` with all the contents\"\"\"\n",
    "    for f in folder.iterdir():\n",
    "        rmdir_rec(f) if f.is_dir() else f.unlink()\n",
    "    folder.rmdir()\n",
    "    \n",
    "    \n",
    "def merge_folders(src: Path, dst: Path, matching_files_policy: {\"skip\", \"replace\", \"rename\", \"error\"} = \"replace\"):\n",
    "    \"\"\"\n",
    "    recursively copies contents from the `src` folder to `dst` folder.\n",
    "    if files match, uses `matching_files_policy`:\n",
    "        - skip\n",
    "        - replace\n",
    "        - error: raises FileExistsError\n",
    "        - rename: adds \".copy\" suffix to filename, eg `a.txt` -> `a.copy.txt`\n",
    "    \"\"\"\n",
    "    assert matching_files_policy in {\"skip\", \"replace\", \"rename\", \"error\"}\n",
    "    \n",
    "    for path_src in src.iterdir():\n",
    "        path_dst = dst / path_src.name\n",
    "        if path_src.is_dir():\n",
    "            path_dst.mkdir(exist_ok=True)\n",
    "            merge_folders(path_src, path_dst, matching_files_policy)\n",
    "        else:\n",
    "            if path_dst.exists():\n",
    "                if matching_files_policy == \"error\":\n",
    "                    raise FileExistsError(path_dst)\n",
    "                elif matching_files_policy == \"replace\":\n",
    "                    path_dst.unlink()\n",
    "                elif matching_files_policy == \"rename\":\n",
    "                    while path_dst.exists():\n",
    "                        path_dst = path_dst.parent / (path_dst.stem + \".copy\" + path_dst.suffix)\n",
    "                else:\n",
    "                    continue\n",
    "            file_copy(path_src, path_dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function copy in module shutil:\n",
      "\n",
      "copy(src, dst, *, follow_symlinks=True)\n",
      "    Copy data and mode bits (\"cp src dst\"). Return the file's destination.\n",
      "    \n",
      "    The destination may be a directory.\n",
      "    \n",
      "    If follow_symlinks is false, symlinks won't be followed. This\n",
      "    resembles GNU's \"cp -P src dst\".\n",
      "    \n",
      "    If source and destination are the same file, a SameFileError will be\n",
      "    raised.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(file_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "RUNTIME_IS_ON_GOOGLE_COLAB: bool = \"google.colab\" in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if on google colab, fetch whole repository\n",
    "# \n",
    "def fetch_lib_from_github() -> (str, \"http message\"):\n",
    "    archive = Path(\"mbs_lib.zip\")\n",
    "    user = \"zudanievil\"\n",
    "    repo = \"MiceBrainMriSegmentation\"\n",
    "    branch = \"paper\"\n",
    "    url = f\"https://api.github.com/repos/{user}/{repo}/zipball/{branch}\" \n",
    "    # https://docs.github.com/en/rest/reference/repos#download-a-repository-archive-tar\n",
    "    dst_dir = \"/content\" # google VM directory for user contents\n",
    "    \n",
    "    zipball, msg = urlretrieve(url)\n",
    "    unzip(src=Path(archive), dst=dst_dir)\n",
    "    Path(archive).unlink()\n",
    "    return f\"{dst_dir}/{user}-{repo}\", msg\n",
    "\n",
    "\n",
    "if RUNTIME_IS_ON_GOOGLE_COLAB:\n",
    "    MBS_LIB_PATH, msg = fetch_lib_from_github()\n",
    "else:\n",
    "    MBS_LIB_PATH = \"./\"\n",
    "\n",
    "sys.path.insert(0, MBS_LIB_PATH)\n",
    "from mbs_lib.core import info_classes as IC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a. creating folders ##\n",
    "classes `IC.ImageFolderInfo`, `IC.OntologyFolderInfo`, `IC.SegmentationResultsFolderInfo` contain `.write()` method that allows to conveniently create these folders in the filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKING_DIR = \"/content/example\" if RUNTIME_IS_ON_GOOGLE_COLAB \\\n",
    "    else YOUR_TEMP_DIRECTORY\n",
    "\n",
    "\n",
    "working_dir = pathlib.Path(WORKING_DIR)\n",
    "working_dir.mkdir(exist_ok=False)\n",
    "\n",
    "infos = {}\n",
    "\n",
    "infos[\"ontology\"] = IC.OntologyFolderInfo(working_dir/\"ontology\")\n",
    "infos[\"ontology\"].write()\n",
    "\n",
    "for i in (1, 2):\n",
    "\n",
    "    infos[f\"images_{i}\"] = IC.ImageFolderInfo(working_dir / f\"images_{i}\")\n",
    "    infos[f\"images_{i}\"].write()\n",
    "\n",
    "    infos[f\"results_{i}\"] = IC.SegmentationResultFolderInfo(\n",
    "        infos[f\"images_{i}\"], infos[\"ontology\"], folder=working_dir / f\"results_{i}\")\n",
    "    infos[f\"results_{i}\"].write()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rmdir_rec(working_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b. putting files into image folder ##\n",
    "* `lib/default_specifications` folder has configuration files that are copied by the `.write()` methods of info classes into the directory that they create. These are YAML files, that can be used to correct the `lib.pipelines` modules' behaviour.\n",
    "* `image_folder_specification.yml` that was is created in `c:/users/user/example/img` must be edited.\n",
    "* under the `file_name_fields` key there is a list of strings, that compose any file name that is related to image. one should give these fields names that correspond to current experiment parameters, like time, mice strain, etc.\n",
    "    > e.g. if configuration looks like this:\n",
    "    file_name_fields:\n",
    "        - a\n",
    "        - b\n",
    "        - c\n",
    "    then image file names are assumed to look like `{a}_{b}_{c}.npy`, and metadata names like `{a}_{b}_{c}.yml`. these names will be broken down by some scripts into \"dictionaries\" of {field_name: field_value}. For instance, name 10_20_xyz.npz will correspond to {\"a\":\"10\", \"b\":\"20\", \"c\":\"xyz\"}.  **It is possible to adjust cropped scan resolution based on the value of \"frame\" field through editing `cropped_image_shapes` in the image folder configuration.**\n",
    "* After that transfer the images into the `img_raw` subfolder of image folder, rename them according to the fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_example():\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. manual scan segmentation ##\n",
    "* manual scan segmentation is done by ImageJ program.\n",
    "* the result of the segmentation for each image is couple files that contain digits separated by tabulations and newlines (ImageJ scripts do not have sophisticated tools for file parsing and formatting). These files are collected by a python script into a single YAML metadata file, based on the values under `metadata keys` in the image folder configuration.\n",
    "* to segment images do the following:\n",
    "    1. make list of file names in `img_raw` subfolder, put it in the `ij_img_list.txt` file in the image folder, separated by newlines (only names, not the full paths). Create `ij_pointer.txt`, put 0 into it. Here is an easy way to o this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_raw_images():\n",
    "    img_list_fname = image_f.folder()/\"ij_img_list.txt\"\n",
    "    raw_img_folder = image_f.raw_image_folder()\n",
    "    img_idx_fname = image_f.folder()/\"ij_pointer.txt\"\n",
    "\n",
    "    with open(img_list_fname, \"wt\") as f:\n",
    "        for img in raw_f.iterdir():\n",
    "            print(img.name, file=f)\n",
    "            \n",
    "    with open(img_idx_fname, \"wt\") as f:\n",
    "        print(0, file=f)\n",
    "        \n",
    "list_raw_images()\n",
    "del list_raw_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   \n",
    "   2. Open the `lib/imagej_scripts/brain_segmentation_with_imagej.txt`, edit command for image opening according to [ImageJ macro guide] and [ImageJ macro functions list] to open your images (the function below comment `//IMAGE OPENING FUNCTION`). Initially it opens 32bit little-endian single channel 256x256, written as a C-array.\n",
    "   1. Open imagej, load that file as imagej macro: `macros > install > imagej`\n",
    "   1. Press `h` to open log window with the instructuions. follow the instructions.\n",
    "   1. Run collect `collect_image_metadata.main()` (cell below)\n",
    "   >you can find about metadata collection process and how to tune it with configuration editing if you run `help(collect_image_metadata.main)`\n",
    "   \n",
    "[ImageJ macro guide]: https://imagej.nih.gov/ij/developer/macro/macros.html#tools\n",
    "[ImageJ macro functions list]: https://imagej.nih.gov/ij/developer/macro/functions.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ADD TQDM PROGRESS BAR TO THIS FUNCTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.pipelines import collect_image_metadata\n",
    "collect_image_metadata.main(image_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4a. downloading atlas images ##\n",
    "variables for downloading are stored in `ontology_folder_specification.yml` file inside ontology folder that you've created above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Edit `atlas_id` and `svg_groups` (a table of them can be found [here](http://help.brain-map.org/display/api/Atlas+Drawings+and+Ontologies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.pipelines import download_svgs\n",
    "download_svgs.download_default_ontology(ontology_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Edit the `slice_coordinates` if you know the coordinates for the first slice and the last slice in the atlas. this allows you to download a list of slice ids and zip it with coordinate range using a script in the cell below (the table is just for utility purposes, you can skip this step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_svgs.download_slice_ids_table(ontology_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have a very readable (for an xml) `default.xml` tree of structures for the atlas, and probably a tabulation-separated table of slice ids.\n",
    "For each frame value in image names there should be an svg image with the same name. fill the ontology folder configuration  `svg_names_and_slice_ids` with pairs of `frame_field_value: slice_id`. run the script from the cell below to bulk-download the atlas vector images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_svgs.download_svgs(ontology_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can and need to manually edit the `.svg` masks with Inkscape, but note that some Inkscape functions can alter all xml attributes of the paths. structures for rendering are found by `structure_id` attributes of the paths, make sure, they are not deleted in the editing process.\n",
    "1. I advise to compute mean of all images for each frame and put it into a corresponding svg (the rendering pipeline ignores visible objects that do not have `structure_id` attribute, so you can leave image there).\n",
    "2. You **must** create a rectangle with xml attribute `structure_id='bbox'`, that will mark the border of the rendered masks (to edit xml attributes of objects from Inkscape, open the 'xml editor' tab.\n",
    "3. It's a good idea to slightly adjust nodes of atlas structures to fit the contours of the brain.\n",
    "4. Note that you can specify an arbitrary function to modify each mask right before the scan segmentation. Therefore you do need to flip/copy/crop the svg masks if only one hemisphere is covered and you need masks for both hemisperes, or otherwise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4b. rendering raster masks ##\n",
    "For this one needs to edit `inkscape_executable_path` value in the ontology folder's configuration. \n",
    "The rendering pipeline uses image folder configuration `cropped_image_shapes` values for determining mask sizes.\n",
    "Details about process can be found in `prerender_masks.main` function documentation. This process might take several hours, but is easily parallelized by calling pipeline from different processes for only a part of all frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.pipelines import prerender_masks\n",
    "prerender_masks.main(ontology_f, image_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. preprocessing scans ##\n",
    "* Convert images to numpy native array format via `numpy.save()`, put them into `img` subfolder of the image folder.\n",
    "\n",
    "* The pipeline called below uses `cropped_image_shapes` key of the configuration and `frame` field value in the image name as well as some metadata keys to crop and resize the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.pipelines import crop_images\n",
    "crop_images.main(image_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To normalize image by intensity, we generate reference values and put them into metadata files. Later on you can choose which key to to use for image normalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.pipelines import generate_intensity_reference\n",
    "generate_intensity_reference.main(image_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. fine anatomical segmentation\n",
    "1. You need to specify a tabulation-separated table which contains names of images. Table header specifies, from which columns images fall into 'control' group and from which -- into the 'effect' group. images from the one row constitute a batch and are compared against each other. the `batch_for_comparison` pipeline can create this table. Note that one can easily edit this table in MS Excel/Libre Office, etc.\n",
    "You can find about how to control pipeline behaviour through a result folder configuration in the `batch_for_comparison.main` description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.pipelines import batch_for_comparison\n",
    "batch_for_comparison.main(result_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. please read the `compare_and_segment.main` help for detalis on how to control it's behaviour with configuration file and some other files, that can be created in the `spec` subfolder of results folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.pipelines import compare_and_segment\n",
    "compare_and_segment.main(result_f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. segmentation results are saved into a temporary folder to save RAM and allow parallel execution (by running several processes and supplying `batch_range` argument to  `compare_and_segment.main`). Because of this design choice, segmentation results' pieces are aggregated by a separate function. You also need to delete temp folder yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_and_segment.collect_segmentation_results(result_f)\n",
    "\n",
    "def cleanup():\n",
    "    fs = result_f.segmentation_temp()\n",
    "    [f.unlink for f in fs.iterdir()]\n",
    "    fs.rmdir()\n",
    "# cleanup()\n",
    "del cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. aftermath\n",
    "There are some scripts for processing the results table. Consult with their descriptions to understand what do they do.\n",
    "also there is an execute_all script, that just calls them in a logical order (some scripts depend on each other). They also use configuration for the results folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures = (\n",
    "    'Main Olfactory Bulb',\n",
    "    'Olfactory Nerve',\n",
    "    'Anterior Olfactory Nucleus',\n",
    "    'Piriform Area',\n",
    "    'Piriform-Amygdalar Area',\n",
    "    'Cortical Amygdalar Area',\n",
    "    'Entorhinal Area',\n",
    "    'Olfactory Tubercle',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_results_processing.execute_all(srfi, structure_list_for_significance_table=structures)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
